# AIOps探索：n8n + DeepSeek 实现错误日志的智能分析

**版权声明** 本文为原创内容，著作权归[Jevanshy]所有。 未经授权**禁止转载**。如需引用或二次创作，请遵守以下规则：

1. **清晰标注**原文标题、作者及原始链接
2. **禁止商业用途**（包括但不限于付费专栏、培训材料）
3. **禁止洗稿**（修改关键代码/截图后伪装原创） 违反者将追究责任。 原文永久地址：





本文将详细拆解一个基于 **n8n**、**Elasticsearch** 和 **DeepSeek-V3** 构建的自动化分析链路。该链路能够每周自动锁定 Top 5 故障应用，并针对高频错误进行根因分析。

------

## 一、 前置准备：让数据与算力就绪

在实现自动化分析之前，需要确保以下基础设施已落地：

1. **日志基座 (ELK/EFK)**：
   - 生产环境日志已统一接入 Elasticsearch。
   - 日志包含标准字段：`app.keyword`（应用标识）、`level.keyword`（日志等级）、`msg.keyword`（错误消息摘要）以及 `stackTrace`（异常堆栈）。
2. **低代码引擎 (n8n)**：用于串联 ES 查询、数据清洗、AI 调用及消息通知的完整流转。
3. **大模型算力 (DeepSeek-V3)**：具备较强逻辑推理能力的 LLM，通过 API 接入，负责对清洗后的日志进行 SRE 维度的深度解读。
4. **推送终端**：企业微信机器人的 Webhook Key。

------

## 二、 核心链路：四步走实现智能分析

整个 AIOps 链路设计思路清晰，采用“由大到小、由浅入深”的过滤策略：

### 第一步：锁定“故障大户” (App-Level Aggregation)

流程启动后，首先通过 `httpRequest` 对 ES 发起第一次聚合查询。

- **过滤条件**：限定过去 7 天内 `level: ERROR` 的数据。
- **核心逻辑**：通过 `terms` 聚合对 `app.keyword` 字段进行计数排名，筛选出报错总数最高的前 5 个应用。
- **目的**：解决“看哪里”的问题，确保精力聚焦在核心矛盾上。

### 第二步：精准捕获高频异常 (Message-Level Aggregation)

锁定 Top 5 应用后，流程会为每个应用分别发起第二次精准查询。

- **操作逻辑**：针对特定 `appName`，通过 `msg.keyword` 字段进行二次聚合。
- **核心产出**：获取该应用下出现频次最高的 **Top 1 错误消息**，并利用 `top_hits` 抽样获取该错误对应的完整 `stackTrace` 和 `method` 信息。
- **目的**：解决“什么错最严重”的问题，为 AI 分析提供高质量的输入样本。

### 第三步：AI 辅助根因定位 (Data Cleaning & AI Agent)

原始堆栈通常包含大量冗余信息，直接发送会消耗大量 Token 且干扰 AI 判断。

- **堆栈脱水**：利用自定义 JS 脚本，通过正则匹配提取 `Caused by:` 根因链，并对每一层级进行截断，只保留最有价值的代码调用行。
- **智能诊断**：将清洗后的数据喂给 AI Agent。并为 DeepSeek 注入了 SRE 专家指令，要求其严禁猜测，必须基于 `method` 和 `stackTrace` 给出具体的优化建议（如：修改连接池参数、增加空闲检查、优化业务判空逻辑等）。

### 第四步：多维度结果触达 (Multi-Channel Output)

分析完成后，流程通过企业微信进行双向反馈：

1. **即时摘要**：在群聊中推送 Markdown 格式的汇总数据，罗列 Top 5 应用及其报错总数，便于快速概览。
2. **详细副本**：将 DeepSeek 生成的深度报告转换为 HTML 格式文件并上传。方便研发人员对报告进行下载预览，查看详细的故障分析和操作建议。

------

## 

